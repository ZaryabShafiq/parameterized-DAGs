
## **Project: Parameterized DAGs**

#### **README.md**
```markdown
# Parameterized DAGs in Apache Airflow (Practice Project)

## Overview
This project introduces **parameterized DAGs** in Apache Airflow.
It shows how to use **parameters** to control the behavior of tasks in a mock ETL pipeline.
This is a **beginner-friendly practice project** that filters customer and sales data based on dynamic inputs (e.g., country or sales channel).

## Features
- **Dynamic ETL Pipeline**: Pass parameters to filter mock datasets.
- **Scalable Design**: Modify parameters to test different filtering criteria.
- **Hands-On Learning**: Designed for those starting with Airflow and ETL pipelines.

## Dataset
The datasets used are:
- **`customer_data.csv`**: Mock customer data.
- **`sales_data.csv`**: Mock sales data.

## Requirements
- Apache Airflow
- Python 3.x
- Pandas
- NumPy

